# ğŸ”¬ GuÃ­a de Sweep W&B - MiniPointNet RTX 5090

## ğŸ“‹ Â¿QuÃ© es un Sweep?

Un **Sweep** de Weights & Biases automatiza la bÃºsqueda de los mejores hiperparÃ¡metros para tu modelo. 

En lugar de entrenar manualmente con diferentes configuraciones, el sweep:
- âœ… Prueba mÃºltiples combinaciones automÃ¡ticamente
- âœ… Usa optimizaciÃ³n Bayesiana (aprende de intentos anteriores)
- âœ… Guarda solo los mejores modelos
- âœ… Nombra cada modelo segÃºn sus hiperparÃ¡metros: `LR0.0027_W28_J0.016`

## ğŸš€ Inicio RÃ¡pido

### Paso 1: Iniciar el Sweep
```bash
./start_sweep_minipointnet.sh
```

Esto crearÃ¡ el sweep en W&B y te darÃ¡ un ID como:
```
tito-ruiz-haros/Point-Cloud-Research/abc123de
```

### Paso 2: Ejecutar Agentes

El script te preguntarÃ¡ si quieres iniciar el agente automÃ¡ticamente. Si dices que sÃ­, comenzarÃ¡ a entrenar modelos.

**O manualmente:**
```bash
wandb agent tito-ruiz-haros/Point-Cloud-Research/abc123de
```

### Paso 3: Monitorear en W&B

Abre tu navegador en:
```
https://wandb.ai/tito-ruiz-haros/Point-Cloud-Research/sweeps
```

VerÃ¡s en tiempo real:
- ğŸ“Š GrÃ¡ficos de IoU vs hiperparÃ¡metros
- ğŸ† El mejor modelo encontrado
- ğŸ“ˆ EvoluciÃ³n del sweep

## âš™ï¸ ConfiguraciÃ³n del Sweep

Archivo: `configs/sweeps/sweep_minipointnet_rtx5090.yaml`

### HiperparÃ¡metros que se optimizan:

| ParÃ¡metro | Rango | DescripciÃ³n |
|-----------|-------|-------------|
| `learning_rate` | 0.0008 - 0.005 | Tasa de aprendizaje |
| `weight_maq` | 20 - 40 | Peso de clase Maquinaria |
| `jitter_sigma` | 0.005 - 0.015 | Ruido de augmentaciÃ³n |

### ParÃ¡metros fijos:
- **Ã‰pocas**: 50 (mÃ¡s rÃ¡pido para sweep)
- **Arquitectura**: MiniPointNet
- **Dataset**: blocks_10m (Dataset 3)

## ğŸ“ OrganizaciÃ³n de Resultados

Los modelos se guardan automÃ¡ticamente en:
```
checkpoints/
â””â”€â”€ SWEEP_RTX5090_MiniPointNet_D3_R1/
    â”œâ”€â”€ LR0.0027_W28_J0.016_BEST_IOU.pth
    â”œâ”€â”€ LR0.0027_W28_J0.016_BEST_LOSS.pth
    â”œâ”€â”€ LR0.0012_W35_J0.008_BEST_IOU.pth
    â”œâ”€â”€ LR0.0012_W35_J0.008_BEST_LOSS.pth
    â””â”€â”€ ...
```

**Nomenclatura:**
- `LR0.0027` = Learning Rate de 0.0027
- `W28` = Weight de Maquinaria = 28
- `J0.016` = Jitter Sigma de 0.016

Cada configuraciÃ³n guarda 2 modelos:
- `*_BEST_IOU.pth` â†’ Mejor IoU de Maquinaria (ğŸ¯ tu prioridad)
- `*_BEST_LOSS.pth` â†’ Mejor pÃ©rdida de validaciÃ³n

## ğŸ›ï¸ Ejecutar MÃºltiples Agentes en Paralelo

Tu RTX 5090 es un misil, pero con sweeps es mejor ir de uno en uno para no saturar:

```bash
# Terminal 1
wandb agent tito-ruiz-haros/Point-Cloud-Research/abc123de
```

Si tienes suficiente RAM y quieres acelerar (opcional):
```bash
# Terminal 2 (solo si tienes >100GB RAM libres)
wandb agent tito-ruiz-haros/Point-Cloud-Research/abc123de
```

## ğŸ›‘ Detener el Sweep

**Detener agente actual:**
```bash
Ctrl + C
```

**Detener el sweep completo en W&B:**
1. Ve a la pÃ¡gina del sweep
2. Click en "Stop Sweep"

## ğŸ“Š Interpretar Resultados

### En W&B verÃ¡s:

**1. Parallel Coordinates Plot**
- LÃ­neas de colores mostrando cada run
- Las lÃ­neas que llegan mÃ¡s arriba en `IoU_Maquinaria` son las mejores

**2. Importance Plot**
- QuÃ© hiperparÃ¡metro tiene mÃ¡s impacto
- Ayuda a entender quÃ© optimizar primero

**3. Table View**
- Tabla con todos los runs ordenados
- Ordena por `IoU_Maquinaria` para ver el mejor

### Mejor Modelo

El sweep guardarÃ¡ el mejor encontrado. Para usarlo en inferencia:

```bash
# Encuentra el mejor modelo en la carpeta
ls -lh checkpoints/SWEEP_RTX5090_MiniPointNet_D3_R1/*_BEST_IOU.pth

# Usa el que tenga mejor IoU (verÃ¡s en W&B cuÃ¡l fue)
python3 inference.py \
  --input data/raw_test/MP_acotado.las \
  --model checkpoints/SWEEP_RTX5090_MiniPointNet_D3_R1/LR0.0027_W28_J0.016_BEST_IOU.pth \
  --architecture MiniPointNet
```

## ğŸ”§ Modificar ConfiguraciÃ³n del Sweep

Edita: `configs/sweeps/sweep_minipointnet_rtx5090.yaml`

### Cambiar rangos de bÃºsqueda:
```yaml
learning_rate:
  min: 0.001  # MÃ­nimo
  max: 0.01   # MÃ¡ximo
```

### Agregar nuevo hiperparÃ¡metro:
```yaml
batch_size:
  values: [128, 256, 512]  # Prueba estos valores
```

DespuÃ©s de editar, vuelve a ejecutar:
```bash
./start_sweep_minipointnet.sh
```

## ğŸ’¡ Tips Avanzados

### 1. Early Termination
El sweep ya tiene configurado Hyperband que detiene runs malos despuÃ©s de 10 Ã©pocas. Esto ahorra tiempo.

### 2. Cambiar MÃ©todo de OptimizaciÃ³n
```yaml
method: random  # BÃºsqueda aleatoria (mÃ¡s simple)
method: grid    # BÃºsqueda exhaustiva (mÃ¡s lento)
method: bayes   # Bayesiano (mÃ¡s inteligente) â† Actual
```

### 3. MÃ¡s Ã‰pocas para el Mejor
Una vez encuentres el mejor, entrÃ©nalo manualmente con 100 Ã©pocas:

```bash
# Edita rtx5090_beast.yaml con los mejores hiperparÃ¡metros
# Luego entrena normal
python3 train_2.py --config configs/minipointnet/rtx5090_beast.yaml
```

## ğŸ¯ Estrategia Recomendada

1. **Fase 1: ExploraciÃ³n RÃ¡pida** (Este sweep)
   - 50 Ã©pocas por run
   - OptimizaciÃ³n Bayesiana
   - Encuentra regiÃ³n prometedora

2. **Fase 2: Refinamiento** (Opcional)
   - Crea nuevo sweep con rangos mÃ¡s estrechos
   - Alrededor de los mejores valores encontrados

3. **Fase 3: Entrenamiento Final**
   - Toma el MEJOR hiperparÃ¡metro set
   - Entrena con 100-150 Ã©pocas
   - Usa ese modelo en producciÃ³n

## ğŸ“ Troubleshooting

**"wandb: command not found"**
```bash
pip install wandb
wandb login
```

**"Sweep keeps failing"**
- Revisa que el config YAML estÃ© bien
- Verifica que `train_2.py` exista
- Checa los logs en W&B

**"Out of memory"**
- Reduce `batch_size` en el config base
- No ejecutes mÃºltiples agentes en paralelo

**"Too many runs"**
- DetÃ©n el sweep en W&B
- Borra runs malos desde la interfaz web

## ğŸ“ˆ MÃ©tricas que se Trackean

Para cada run el sweep guarda:
- âœ… `IoU_Maquinaria` (objetivo principal)
- âœ… `IoU_Suelo`
- âœ… `mIoU` (promedio)
- âœ… `val_loss`
- âœ… `accuracy`
- âœ… `learning_rate` actual
- âœ… Curvas de entrenamiento por Ã©poca

## ğŸ† Ejemplo de Resultados Esperados

DespuÃ©s de ~10-15 runs podrÃ­as ver algo como:

| Run | LR | Weight | Jitter | IoU_Maq | mIoU |
|-----|-----|--------|--------|---------|------|
| ğŸ¥‡ LR0.0027_W28_J0.012 | 0.0027 | 28 | 0.012 | **88.5%** | 93.2% |
| ğŸ¥ˆ LR0.0015_W32_J0.008 | 0.0015 | 32 | 0.008 | 87.3% | 92.8% |
| ğŸ¥‰ LR0.0031_W25_J0.014 | 0.0031 | 25 | 0.014 | 86.8% | 92.5% |

El ğŸ¥‡ es tu modelo ganador!

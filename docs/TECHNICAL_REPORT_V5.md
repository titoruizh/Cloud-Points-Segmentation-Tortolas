# Informe T√©cnico V5: "Geometric Purification" (Verticality Ablation) üìâ
**Versi√≥n:** 5.0 (Ablation Study)
**Fecha:** 12 Enero 2026
**Autor:** Antigravity AI & Usuario
**Estado:** üß™ Experimento en Curso

---

## 1. Hip√≥tesis V5: ¬øLa Verticalidad nos Miente? ü§î
En V4 logramos excelentes m√©tricas (IoU 83%), pero observamos problemas persistentes en:
1.  **Techos:** A menudo se confunden con suelo.
2.  **Pretiles:** Muros bajos confundidos con maquinaria.

**Teor√≠a:** La feature de "Verticalidad" (1-|Nz|) fuerza al modelo a aprender que "Pared = Maquinaria" y "Plano = Suelo". Esto es cierto para el chasis, pero **falso para el techo** (que es plano) y **falso para el suelo inclinado**.
Al eliminar este canal expl√≠cito, forzamos al modelo (PointNet++) a aprender la *forma tridimensional completa* en lugar de depender de un "truco" local como la normal Z.

---

## 2. Definici√≥n T√©cnica V5 üõ†Ô∏è

### 2.1 Nueva Dimensionalidad (`d_in = 9`)
Eliminamos la verticalidad explicita.

| Canal | Descripci√≥n |
| :--- | :--- |
| **0-2** | X, Y, Z (Normalizados) |
| **3-5** | R, G, B (Normalizados) |
| **6-8** | Nx, Ny, Nz (Normales de superficie) |
| **~~9~~** | ~~Verticalidad~~ (ELIMINADO ‚ùå) |

### 2.2 Estrategia de Datos
*   **Source:** `data/raw RGB`
*   **Target:** `data/processed/blocks_10m V5`
*   **Script:** `scripts/preprocessing/V5/preprocess_blocks_10m_v5.py`

---

## 3. Resultados Esperados
*   **Posible ca√≠da en IoU inicial:** La verticalidad es una feature muy fuerte ("chivato"). Sin ella, el entrenamiento podr√≠a tardar m√°s en converger, pero el resultado deber√≠a ser m√°s robusto geom√©tricamente.

---

## 4. An√°lisis de Datos y Estrategia de Entrenamiento üìäüí™

Antes de entrenar, ejecutamos un an√°lisis exhaustivo del dataset generado (`data/processed/blocks_10m V5`).

### 4.1 Estad√≠sticas del Dataset V5
*   **Total Bloques:** 837
*   **Distribuci√≥n de Bloques:**
    *   üöú Machinery: 246 (29.4%)
    *   ‚õ∞Ô∏è Hard Negative: 238 (28.4%) - *Muros y pendientes fuertes*
    *   üü§ Easy Negative: 353 (42.2%)
*   **Balance de Puntos:**
    *   Suelo (0): 95.78%
    *   Maquinaria (1): 4.22%
*   **Ratio de Desbalance:** **22.7 : 1** (Por cada punto de m√°quina hay ~23 de suelo).

### 4.2 Configuraci√≥n de Entrenamiento (`pointnet2_v5_novert.yaml`)
Basado en el an√°lisis, ajustamos los hiperpar√°metros para compensar la falta de la feature "Verticalidad" y el desbalance de clases.

1.  **Class Weights `[1.0, 15.0]`:**
    *   Optamos por un peso conservador (15.0) en lugar del ratio puro (23.0) para evitar falsos positivos excesivos, confiando en el oversampling para llenar el gap.
2.  **Runtime Oversampling (Factor 4x):**
    *   Se implement√≥ `oversample_machinery: 4` en el configuraci√≥n.
    *   **Efecto:** Vemos la maquinaria 5 veces m√°s frecuentemente por √©poca (1 real + 4 copias), reduciendo el desbalance efectivo a ~4:1.
3.  **Scheduler: `CosineAnnealingLR`:**
    *   A diferencia de `StepLR` (V4), usamos un decaimiento coseno para una convergencia m√°s suave, permitiendo al modelo explorar m√≠nimos m√°s robustos sin cambios bruscos de LR.
4.  **Loader V5 (`src.data.dataset_v5`):**
    *   Se cre√≥ un cargador espec√≠fico para manejar `d_in=9` (10 columnas en disco).
    *   **Pipeline:** XYZ -> Augmentation -> Feature Stacking (XYZ+RGB+Normals) -> Tensor.

**Estado Actual:**
*   Explorando `LR [0.0005, 0.001]` y `Weights [15, 20, 25]`.

---

## 5. Inferencia V5.2: "Nitro" üèéÔ∏èüí®

Para hacer frente a nubes de puntos masivas (100M+ puntos) en la RTX 5090, hemos desarrollado una nueva versi√≥n del motor de inferencia: `scripts/inference/infer_pointnet_v5.2.py`.

### 5.1 Optimizaciones Clave
1.  **Lectura Directa de Normales:** Si el archivo LAS ya trae normales (`normal_x`, `vl_x`...), el script las lee directamente sin recalcularlas con Open3D. Ahorro de tiempo: **~60-80%** en pre-procesamiento.
2.  **Gridding Vectorizado:** Reemplazo de bucles Python por operaciones vectorizadas de Numpy para dividir la nube en bloques de 10x10m.
3.  **Inferencia FP16 (AMP):** Uso de `torch.amp.autocast` para reducir el uso de memoria VRAM y aprovechar los Tensor Cores.
4.  **Carga "Nitro":** Pre-allocaci√≥n de tensores en memoria continua para maximizar el ancho de banda hacia la GPU.

### 5.2 Configuraci√≥n Recomendada (RTX 5090)
*   **Batch Size:** `64` (Est√°ndar Seguro) o `96` (Agresivo).
    *   *Nota:* Intentar `256` caus√≥ OOM (>20GB VRAM de alocaci√≥n) debido a la expansi√≥n de tensores internos de PointNet++.
*   **Torch Compile:** Opcional (`--no_compile false`). Acelera el grafo, pero a√±ade overhead de inicio (1-2 min).

**Comando:**
```bash
python3 scripts/inference/infer_pointnet_v5.2.py \
  --input_file "ruta/nube.laz" \
  --checkpoint "ruta/best_model.pth" \
  --batch_size 64
```




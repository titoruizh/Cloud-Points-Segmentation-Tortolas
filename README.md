# Cloud Point Research V2 ‚Äî Portafolio T√©cnico

Proyecto de investigaci√≥n y desarrollo en GeoAI: segmentaci√≥n binaria (maquinaria vs. suelo) sobre nubes fotogram√©tricas. Este repositorio es una muestra de trabajo t√©cnico (no un paquete listo para uso externo). Enfocado en reproducibilidad experimental, MLOps y optimizaci√≥n de throughput para producci√≥n.


üîç Resultados de segmentaci√≥n (RGB vs Clasificado)
Escena 1
RGB	Segmentaci√≥n
<img src="https://github.com/user-attachments/assets/a584df28-2917-4167-a05f-20556c8de400" width="100%">	<img src="https://github.com/user-attachments/assets/f1ebb32e-e2d4-46c4-829d-bb398ad27c96" width="100%">
Escena 2
RGB	Segmentaci√≥n
<img src="https://github.com/user-attachments/assets/43a6eb27-c57d-46ab-b539-cc4895ea850b" width="100%">	<img src="https://github.com/user-attachments/assets/b0492563-e778-49b0-8b78-a33faa36da00" width="100%">


**Estado:** Modelo V6 (Resolution Sync, 0.25m) validado y listo para despliegue local.

**Resumen t√©cnico ‚Äî puntos clave:**
- **Arquitectura:** PointNet++ MSG (entrada: XYZ + RGB + Normals, d_in = 9)
- **Estrategia:** Sincronizar resoluci√≥n de entrenamiento/inferencia a 0.25 m ("Resolution Sync") para eliminar domain-gap.
- **Datos:** bloques 10x10 m procesados en `data/processed/blocks_10m V6`.
- **Puntos por muestra:** 2048 (evaluado para densidad 0.25m).
- **Clase desequilibrada:** uso de `class_weights` (ej. [1.0, 15.0]) y oversampling de maquinaria para estabilidad.

**M√©tricas V6 (mejor corrida validada)**
- **mIoU (val):** 93.06%
- **IoU Maquinaria:** 87.67% (mejor hist√≥rico 88.85%)
- **IoU Suelo:** 98.46%
- **Val Loss:** 0.0227

Detalles completos en: [docs/TECHNICAL_REPORT_V6.md](docs/TECHNICAL_REPORT_V6.md)

**Hardware y entorno de entrenamiento**
- **GPU:** RTX 5090 (entreno en CUDA, Torch + FP16 soporte)
- **Par√°metros sys:** `num_workers=8`, `pin_memory=True`
- **Entrenamiento:** 75 epochs, `batch_size=64`, `num_points=2048`, `learning_rate‚âà0.001`, `base_radius=3.5m`.

**MLOps / Reproducibilidad**
- Experimentos y sweeps con Weights & Biases (`project: Tortolas-segmentation`, `entity: tito-ruiz-haros`).
- Configs versionadas: `configs/pointnet2/pointnet2_v6_0.25m.yaml`, sweeps en `configs/pointnet2/sweep_v6_0.25m.yaml`.
- Checkpoints guardados en `checkpoints/` con metadata de run (logs wandb en `wandb/`).

**T√©cnicas y optimizaciones aplicadas**
- PointNet++ MSG para robustez multi-escala.
- Data-centric: resoluci√≥n y bloqueo espacial (10x10 m) para consistencia geom√©trica.
- Mining de ejemplos dif√≠ciles y pesos de clase para abordar la rareza de maquinaria.
- Inferencia optimizada: Torch Compile, FP16, gridding vectorizado y c√°lculo de normales on-the-fly.

**Proceso de anotaci√≥n y flujo de trabajo (workflow)**
- **Clasificaci√≥n manual primero:** etiquetado manual y reglas heur√≠sticas para bootstrap.
- Dataset curado y balanceado (sobremuestreo de maquinaria y verificaci√≥n visual).
- Entrenamiento ‚Üí evaluaci√≥n (mIoU/IoU por clase) ‚Üí sweep de hiperpar√°metros ‚Üí checkpoint final.

**Resultados de inferencia (ejemplo)**
- Procesamiento: 5,581 bloques ‚Üí ~58 segundos (pipeline optimizado, batch inference).

**Comandos r√°pidos (reproducir / inferir)**

Reproducir entrenamiento V6 (ejemplo):

```bash
python3 TRAIN_V6.py --config configs/pointnet2/pointnet2_v6_0.25m.yaml
```

Inferencia (ejemplo):

```bash
python3 scripts/inference/infer_pointnet_v6.py \
  --input_file "data/raw_test/RGB/entrada_0.25.laz" \
  --checkpoint "checkpoints/SWEEP_RTX 5090 PointNet2 V6 (0.25m)/BEST_IOU.pth" \
  --output_file "data/predictions_v6/salida.laz" \
  --batch_size 64 \
  --confidence 0.8
```



<img width="1046" height="467" alt="image" src="https://github.com/user-attachments/assets/570dd147-8202-4ba0-b075-9de12265bd68" />